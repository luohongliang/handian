{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing `corpus.py`\n",
    "Now that you know how to run a cell, we can begin interacting with the topic models. First we will import your corpus objects. Select and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebook, using serial load function.\n",
      "[20, 40, 60, 80, 100]\n",
      "/home/hongliang/inpho/handian/compare/handian2and2mac/models/handian2-freq5-freq2-N23231312-LDA-K{0}-document-1000.npz\n"
     ]
    }
   ],
   "source": [
    "from corpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now have access to several variables, the most important of which are:\n",
    " -  `c` -- The `vsm.Corpus` object\n",
    " -  `lda_v` -- A dictionary containing each of the `vsm.LdaViewer` instances. You can access a particular model with `lda_v[k]`, substituting k for a particular number, like `lda_v[20]` for the 20-topic model. If the model for that number of topics has not been trained, it will error.\n",
    " -  `topic_range` -- A list of the trained models (e.g., `[20, 40, 60, 80]`)\n",
    " -  `context_type` -- A string containing the particular context type modeled (e.g., `\"sentence\"`, `\"document\"`, `\"article\"`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the `vsm` module\n",
    "\n",
    "The InPhO Topic Explorer is comprised of two modules:\n",
    "1. The `topicexplorer` module contains code for the visualization and user interfaces.\n",
    "2. The `vsm` module contains code for modeling differnet corpora. \n",
    "\n",
    "In order to make use of the term frequency (TF), term frequency-inverse document frequency (TfIdf), and latent semantic analysis (LSA) models, we must import the main vsm module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vsm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the Corpus: Term Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above has loaded your `Corpus` object into the `c` variable. You can see the list of all words that are in your corpus by typing `c.words` into a code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15293"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it only shows the first few and last few unique words in the corpus, alphabetically sorted. \n",
    "\n",
    "What if we want to get a list of how often each word occurs? For that, we can use the `vsm.model.TF` to build a frequency distribution over the terms in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"4\">Collection Frequencies</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Counts                    </th><th style=\"text-align: center; background: #EFF2FB; \">Word                    </th><th style=\"text-align: center; background: #EFF2FB; \">Counts                    </th></tr><tr><td>年                          </td><td>501196                     </td><td>南                          </td><td>273696                     </td></tr><tr><td>王                          </td><td>410631                     </td><td>将                          </td><td>272349                     </td></tr><tr><td>州                          </td><td>383224                     </td><td>行                          </td><td>272075                     </td></tr><tr><td>天                          </td><td>367499                     </td><td>国                          </td><td>257069                     </td></tr><tr><td>月                          </td><td>330868                     </td><td>山                          </td><td>256549                     </td></tr><tr><td>日                          </td><td>316454                     </td><td>官                          </td><td>245958                     </td></tr><tr><td>书                          </td><td>309290                     </td><td>道                          </td><td>245572                     </td></tr><tr><td>军                          </td><td>295896                     </td><td>百                          </td><td>242402                     </td></tr><tr><td>时                          </td><td>294532                     </td><td>臣                          </td><td>241921                     </td></tr><tr><td>文                          </td><td>277990                     </td><td>东                          </td><td>235142                     </td></tr></table>"
      ],
      "text/plain": [
       "LabeledColumn([(u'\\u5e74', 501196), (u'\\u738b', 410631), (u'\\u5dde', 383224), ...,\n",
       "       (u'\\u8858',      6), (u'\\u5ccd',      6), (u'\\u8625',      6)], \n",
       "      dtype=[('word', '<U4'), ('value', '<i8')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model and create a TfViewer object\n",
    "tf = TF(c, context_type)\n",
    "tf.train()\n",
    "tf_v = TfViewer(c, tf)\n",
    "\n",
    "# print the most frequent terms in the document\n",
    "# remember that IPython automatically prints the last cell of a document\n",
    "tf_v.coll_freqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, you should see a table with the 20 most frequently used words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interacting with Topic Models\n",
    "\n",
    "The InPhO Topic Explorer doesn't just work with term frequencies though - it creates LDA topic models. Through the notebook interface these models can be powerfully manipulated to produce new analyses.\n",
    "\n",
    "First, let's select a primary model to investigate, and load it into the variable `v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Loading LDA data from /home/hongliang/inpho/handian/compare/handian2and2mac/models/handian2-freq5-freq2-N23231312-LDA-K20-document-1000.npz\n"
     ]
    }
   ],
   "source": [
    "# print the number of topics in the first model\n",
    "print topic_range[0]\n",
    "# remember that list indexes start with 0 not 1!\n",
    "\n",
    "# replace 'topic_range[0]' with a specific number, if you like\n",
    "k = topic_range[0]\n",
    "\n",
    "# load the topic model\n",
    "v = lda_v[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code loads the first topic model into a viewer object. We have used the `topic_range[0]` instead of simply stating a number so that this same demo notebook will work with any model settings you've prepared. This portability enables us to write analyses that can be replicated across any corpus, and is one of the real strengths of using the `from corpus import *` model of coding your notebooks. If others are using the Topic Explorer to generate their objects, they can run the exact same analysis on different corpora, so long as the variable names are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `v.topics()`\n",
    "First, lets print a list of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan            =\"11\">Topics Sorted by Index</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\"                  >Topic</th><th style=\"text-align: center; background: #EFF2FB;\"                  >Words</th></tr><tr><td style=\"padding-left:0.75em;\">Topic 0</td><td> 官, 司, 部, 郎, 书, 史, 州, 士, 侍, 御           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 1</td><td> 卷, 书, 文, 本, 诗, 传, 集, 记, 经, 纪           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 2</td><td> 年, 王, 帝, 太, 书, 宗, 元, 时, 文, 国           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 3</td><td> 年, 江, 尔, 督, 总, 兵, 部, 抚, 南, 命           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 4</td><td> 月, 日, 年, 星, 辰, 度, 壬, 辛, 庚, 甲           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 5</td><td> 气, 服, 热, 水, 病, 黄, 治, 血, 寒, 阳           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 6</td><td> 官, 本, 钱, 年, 臣, 日, 百, 路, 州, 司           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 7</td><td> 师, 法, 佛, 经, 道, 僧, 生, 时, 王, 门           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 8</td><td> 王, 侯, 国, 齐, 年, 义, 正, 文, 郑, 礼           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 9</td><td> 德, 阙, 天, 圣, 臣, 心, 道, 将, 神, 明           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 10</td><td> 心, 道, 生, 理, 学, 物, 能, 天, 处, 明           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 11</td><td> 天, 乐, 地, 物, 音, 声, 象, 正, 分, 神           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 12</td><td> 王, 帝, 年, 汉, 国, 太, 侯, 武, 秦, 元           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 13</td><td> 山, 金, 风, 日, 诗, 玉, 高, 生, 飞, 光           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 14</td><td> 军, 兵, 将, 州, 城, 遣, 战, 贼, 马, 守           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 15</td><td> 军, 将, 史, 刺, 王, 州, 阳, 司, 郡, 魏           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 16</td><td> 卷, 花, 风, 山, 时, 春, 日, 归, 月, 年           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 17</td><td> 县, 州, 南, 东, 山, 西, 里, 水, 年, 北           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 18</td><td> 礼, 祭, 服, 庙, 祀, 位, 皇, 拜, 西, 门           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 19</td><td> 能, 天, 臣, 民, 死, 行, 时, 道, 心, 已           </td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(u'\\u5b98',   2.89241169e-02), (u'\\u53f8',   1.83126163e-02),\n",
       "        (u'\\u90e8',   1.82221588e-02), ..., (u'\\u5c71',   3.07261927e-09),\n",
       "        (u'\\u91cd',   3.07261927e-09), (u'\\u5e08',   3.07261927e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5377',   3.62639800e-02), (u'\\u4e66',   3.48049589e-02),\n",
       "        (u'\\u6587',   3.20340768e-02), ..., (u'\\u5fc3',   3.61515284e-09),\n",
       "        (u'\\u5175',   3.61515284e-09), (u'\\u5929',   3.61515284e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e74',   1.38180424e-02), (u'\\u738b',   1.26614375e-02),\n",
       "        (u'\\u5e1d',   9.52988584e-03), ..., (u'\\u4f24',   7.22046478e-10),\n",
       "        (u'\\u949e',   7.22046478e-10), (u'\\u5c40',   7.22046478e-10)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e74',   2.11699735e-02), (u'\\u6c5f',   9.63276625e-03),\n",
       "        (u'\\u5c14',   9.37747024e-03), ..., (u'\\u620a',   4.45998216e-09),\n",
       "        (u'\\u4e50',   3.56798568e-09), (u'\\u5fc3',   3.56798568e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6708',   8.66454020e-02), (u'\\u65e5',   3.10259927e-02),\n",
       "        (u'\\u5e74',   2.32652668e-02), ..., (u'\\u7272',   5.16128651e-09),\n",
       "        (u'\\u7cbe',   5.16128651e-09), (u'\\u80e1',   5.16128651e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c14',   2.08837111e-02), (u'\\u670d',   1.05144707e-02),\n",
       "        (u'\\u70ed',   1.00376792e-02), ..., (u'\\u897f',   6.27515240e-09),\n",
       "        (u'\\u81e3',   6.27515240e-09), (u'\\u671b',   6.27515240e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5b98',   1.32533209e-02), (u'\\u672c',   1.06211668e-02),\n",
       "        (u'\\u94b1',   1.00115519e-02), ..., (u'\\u5c09',   2.70603473e-09),\n",
       "        (u'\\u5fae',   2.70603473e-09), (u'\\u5f1f',   2.70603473e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e08',   2.05015671e-02), (u'\\u6cd5',   1.46218594e-02),\n",
       "        (u'\\u4f5b',   1.34508619e-02), ..., (u'\\u7406',   4.55417348e-09),\n",
       "        (u'\\u653b',   4.55417348e-09), (u'\\u6c11',   4.55417348e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   2.29361821e-02), (u'\\u4faf',   1.59475636e-02),\n",
       "        (u'\\u56fd',   1.47913275e-02), ..., (u'\\u5e1d',   3.87619803e-09),\n",
       "        (u'\\u5960',   3.87619803e-09), (u'\\u5c09',   3.87619803e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fb7',   9.12500639e-03), (u'\\u9619',   7.41119822e-03),\n",
       "        (u'\\u5929',   6.97619701e-03), ..., (u'\\u4e16',   2.52672749e-09),\n",
       "        (u'\\u90e8',   2.52672749e-09), (u'\\u897f',   2.52672749e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fc3',   1.70977991e-02), (u'\\u9053',   1.68665014e-02),\n",
       "        (u'\\u751f',   1.48627926e-02), ..., (u'\\u96e8',   4.22988933e-09),\n",
       "        (u'\\u5434',   4.22988933e-09), (u'\\u96ea',   4.22988933e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5929',   1.97012145e-02), (u'\\u4e50',   1.21612754e-02),\n",
       "        (u'\\u5730',   9.83726233e-03), ..., (u'\\u64b0',   4.74006878e-09),\n",
       "        (u'\\u53d1',   4.74006878e-09), (u'\\u5fc3',   3.79205467e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   3.85586880e-02), (u'\\u5e1d',   2.40322594e-02),\n",
       "        (u'\\u5e74',   2.13070977e-02), ..., (u'\\u96be',   3.42563133e-09),\n",
       "        (u'\\u5dde',   0.00000000e+00), (u'\\u519b',   0.00000000e+00)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c71',   9.92226601e-03), (u'\\u91d1',   7.85359181e-03),\n",
       "        (u'\\u98ce',   7.69121014e-03), ..., (u'\\u51e0',   2.20858198e-09),\n",
       "        (u'\\u5bb3',   2.20858198e-09), (u'\\u5377',   1.76686554e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u519b',   2.99340766e-02), (u'\\u5175',   2.95866933e-02),\n",
       "        (u'\\u5c06',   2.10680012e-02), ..., (u'\\u8bae',   2.23479790e-09),\n",
       "        (u'\\u52a0',   2.23479790e-09), (u'\\u4eb2',   2.23479790e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u519b',   3.50015722e-02), (u'\\u5c06',   2.84621175e-02),\n",
       "        (u'\\u53f2',   1.51996771e-02), ..., (u'\\u80fd',   3.11028181e-09),\n",
       "        (u'\\u4f20',   3.11028181e-09), (u'\\u6587',   3.11028181e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5377',   1.16719911e-02), (u'\\u82b1',   1.01826647e-02),\n",
       "        (u'\\u98ce',   8.22209194e-03), ..., (u'\\u8f9e',   2.27822738e-09),\n",
       "        (u'\\u6cb3',   2.27822738e-09), (u'\\u53d8',   2.27822738e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u53bf',   3.18251066e-02), (u'\\u5dde',   2.98520438e-02),\n",
       "        (u'\\u5357',   2.79786121e-02), ..., (u'\\u6708',   2.18646301e-09),\n",
       "        (u'\\u5fc3',   2.18646301e-09), (u'\\u751f',   2.18646301e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u793c',   2.29790080e-02), (u'\\u796d',   1.66786518e-02),\n",
       "        (u'\\u670d',   1.13498690e-02), ..., (u'\\u98ce',   4.00337763e-09),\n",
       "        (u'\\u5c71',   4.00337763e-09), (u'\\u5fc3',   4.00337763e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u80fd',   1.28621757e-02), (u'\\u5929',   1.17718065e-02),\n",
       "        (u'\\u81e3',   1.09651582e-02), ..., (u'\\u8ba8',   1.54701973e-09),\n",
       "        (u'\\u90d1',   1.54701973e-09), (u'\\u9ad8',   1.54701973e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the number of words printed per topic, use the `print_len` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan            =\"21\">Topics Sorted by Index</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\"                  >Topic</th><th style=\"text-align: center; background: #EFF2FB;\"                  >Words</th></tr><tr><td style=\"padding-left:0.75em;\">Topic 0</td><td> 官, 司, 部, 郎, 书, 史, 州, 士, 侍, 御, 军, 府, 正, 品, 都, 学, 监, 尚, 制, 置           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 1</td><td> 卷, 书, 文, 本, 诗, 传, 集, 记, 经, 纪, 志, 古, 学, 篇, 汉, 录, 百, 史, 类, 名           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 2</td><td> 年, 王, 帝, 太, 书, 宗, 元, 时, 文, 国, 州, 臣, 天, 德, 明, 朝, 皇, 日, 安, 官           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 3</td><td> 年, 江, 尔, 督, 总, 兵, 部, 抚, 南, 命, 山, 军, 阿, 海, 官, 克, 巡, 民, 西, 贼           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 4</td><td> 月, 日, 年, 星, 辰, 度, 壬, 辛, 庚, 甲, 丙, 戊, 癸, 分, 午, 天, 巳, 卯, 寅, 亥           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 5</td><td> 气, 服, 热, 水, 病, 黄, 治, 血, 寒, 阳, 生, 汤, 药, 阴, 脉, 痛, 味, 白, 食, 虚           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 6</td><td> 官, 本, 钱, 年, 臣, 日, 百, 路, 州, 司, 令, 诏, 法, 月, 民, 奏, 行, 已, 万, 千           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 7</td><td> 师, 法, 佛, 经, 道, 僧, 生, 时, 王, 门, 天, 山, 日, 寺, 名, 真, 身, 罗, 行, 禅           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 8</td><td> 王, 侯, 国, 齐, 年, 义, 正, 文, 郑, 礼, 父, 晋, 传, 周, 伯, 书, 楚, 服, 师, 母           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 9</td><td> 德, 阙, 天, 圣, 臣, 心, 道, 将, 神, 明, 命, 功, 实, 表, 风, 灵, 文, 载, 成, 礼           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 10</td><td> 心, 道, 生, 理, 学, 物, 能, 天, 处, 明, 时, 性, 义, 先, 意, 行, 圣, 气, 本, 仁           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 11</td><td> 天, 乐, 地, 物, 音, 声, 象, 正, 分, 神, 德, 尺, 百, 木, 成, 小, 马, 生, 应, 时           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 12</td><td> 王, 帝, 年, 汉, 国, 太, 侯, 武, 秦, 元, 皇, 封, 立, 时, 高, 阳, 天, 平, 东, 安           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 13</td><td> 山, 金, 风, 日, 诗, 玉, 高, 生, 飞, 光, 游, 天, 水, 乐, 清, 流, 白, 龙, 行, 石           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 14</td><td> 军, 兵, 将, 州, 城, 遣, 战, 贼, 马, 守, 攻, 都, 西, 金, 万, 李, 死, 败, 杀, 河           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 15</td><td> 军, 将, 史, 刺, 王, 州, 阳, 司, 郡, 魏, 骑, 太守, 尚, 书, 武, 祖, 征, 督, 尉, 城           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 16</td><td> 卷, 花, 风, 山, 时, 春, 日, 归, 月, 年, 江, 水, 夜, 白, 秋, 雨, 天, 前, 老, 处           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 17</td><td> 县, 州, 南, 东, 山, 西, 里, 水, 年, 北, 城, 河, 百, 置, 江, 府, 郡, 阳, 元, 流           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 18</td><td> 礼, 祭, 服, 庙, 祀, 位, 皇, 拜, 西, 门, 东, 神, 官, 前, 帝, 宾, 乐, 日, 仪, 太           </td></tr><tr><td style=\"padding-left:0.75em;\">Topic 19</td><td> 能, 天, 臣, 民, 死, 行, 时, 道, 心, 已, 士, 日, 将, 生, 国, 足, 家, 治, 以为, 世           </td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(u'\\u5b98',   2.89241169e-02), (u'\\u53f8',   1.83126163e-02),\n",
       "        (u'\\u90e8',   1.82221588e-02), ..., (u'\\u5c71',   3.07261927e-09),\n",
       "        (u'\\u91cd',   3.07261927e-09), (u'\\u5e08',   3.07261927e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5377',   3.62639800e-02), (u'\\u4e66',   3.48049589e-02),\n",
       "        (u'\\u6587',   3.20340768e-02), ..., (u'\\u5fc3',   3.61515284e-09),\n",
       "        (u'\\u5175',   3.61515284e-09), (u'\\u5929',   3.61515284e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e74',   1.38180424e-02), (u'\\u738b',   1.26614375e-02),\n",
       "        (u'\\u5e1d',   9.52988584e-03), ..., (u'\\u4f24',   7.22046478e-10),\n",
       "        (u'\\u949e',   7.22046478e-10), (u'\\u5c40',   7.22046478e-10)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e74',   2.11699735e-02), (u'\\u6c5f',   9.63276625e-03),\n",
       "        (u'\\u5c14',   9.37747024e-03), ..., (u'\\u620a',   4.45998216e-09),\n",
       "        (u'\\u4e50',   3.56798568e-09), (u'\\u5fc3',   3.56798568e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6708',   8.66454020e-02), (u'\\u65e5',   3.10259927e-02),\n",
       "        (u'\\u5e74',   2.32652668e-02), ..., (u'\\u7272',   5.16128651e-09),\n",
       "        (u'\\u7cbe',   5.16128651e-09), (u'\\u80e1',   5.16128651e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u6c14',   2.08837111e-02), (u'\\u670d',   1.05144707e-02),\n",
       "        (u'\\u70ed',   1.00376792e-02), ..., (u'\\u897f',   6.27515240e-09),\n",
       "        (u'\\u81e3',   6.27515240e-09), (u'\\u671b',   6.27515240e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5b98',   1.32533209e-02), (u'\\u672c',   1.06211668e-02),\n",
       "        (u'\\u94b1',   1.00115519e-02), ..., (u'\\u5c09',   2.70603473e-09),\n",
       "        (u'\\u5fae',   2.70603473e-09), (u'\\u5f1f',   2.70603473e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5e08',   2.05015671e-02), (u'\\u6cd5',   1.46218594e-02),\n",
       "        (u'\\u4f5b',   1.34508619e-02), ..., (u'\\u7406',   4.55417348e-09),\n",
       "        (u'\\u653b',   4.55417348e-09), (u'\\u6c11',   4.55417348e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   2.29361821e-02), (u'\\u4faf',   1.59475636e-02),\n",
       "        (u'\\u56fd',   1.47913275e-02), ..., (u'\\u5e1d',   3.87619803e-09),\n",
       "        (u'\\u5960',   3.87619803e-09), (u'\\u5c09',   3.87619803e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fb7',   9.12500639e-03), (u'\\u9619',   7.41119822e-03),\n",
       "        (u'\\u5929',   6.97619701e-03), ..., (u'\\u4e16',   2.52672749e-09),\n",
       "        (u'\\u90e8',   2.52672749e-09), (u'\\u897f',   2.52672749e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5fc3',   1.70977991e-02), (u'\\u9053',   1.68665014e-02),\n",
       "        (u'\\u751f',   1.48627926e-02), ..., (u'\\u96e8',   4.22988933e-09),\n",
       "        (u'\\u5434',   4.22988933e-09), (u'\\u96ea',   4.22988933e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5929',   1.97012145e-02), (u'\\u4e50',   1.21612754e-02),\n",
       "        (u'\\u5730',   9.83726233e-03), ..., (u'\\u64b0',   4.74006878e-09),\n",
       "        (u'\\u53d1',   4.74006878e-09), (u'\\u5fc3',   3.79205467e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u738b',   3.85586880e-02), (u'\\u5e1d',   2.40322594e-02),\n",
       "        (u'\\u5e74',   2.13070977e-02), ..., (u'\\u96be',   3.42563133e-09),\n",
       "        (u'\\u5dde',   0.00000000e+00), (u'\\u519b',   0.00000000e+00)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5c71',   9.92226601e-03), (u'\\u91d1',   7.85359181e-03),\n",
       "        (u'\\u98ce',   7.69121014e-03), ..., (u'\\u51e0',   2.20858198e-09),\n",
       "        (u'\\u5bb3',   2.20858198e-09), (u'\\u5377',   1.76686554e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u519b',   2.99340766e-02), (u'\\u5175',   2.95866933e-02),\n",
       "        (u'\\u5c06',   2.10680012e-02), ..., (u'\\u8bae',   2.23479790e-09),\n",
       "        (u'\\u52a0',   2.23479790e-09), (u'\\u4eb2',   2.23479790e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u519b',   3.50015722e-02), (u'\\u5c06',   2.84621175e-02),\n",
       "        (u'\\u53f2',   1.51996771e-02), ..., (u'\\u80fd',   3.11028181e-09),\n",
       "        (u'\\u4f20',   3.11028181e-09), (u'\\u6587',   3.11028181e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u5377',   1.16719911e-02), (u'\\u82b1',   1.01826647e-02),\n",
       "        (u'\\u98ce',   8.22209194e-03), ..., (u'\\u8f9e',   2.27822738e-09),\n",
       "        (u'\\u6cb3',   2.27822738e-09), (u'\\u53d8',   2.27822738e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u53bf',   3.18251066e-02), (u'\\u5dde',   2.98520438e-02),\n",
       "        (u'\\u5357',   2.79786121e-02), ..., (u'\\u6708',   2.18646301e-09),\n",
       "        (u'\\u5fc3',   2.18646301e-09), (u'\\u751f',   2.18646301e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u793c',   2.29790080e-02), (u'\\u796d',   1.66786518e-02),\n",
       "        (u'\\u670d',   1.13498690e-02), ..., (u'\\u98ce',   4.00337763e-09),\n",
       "        (u'\\u5c71',   4.00337763e-09), (u'\\u5fc3',   4.00337763e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')]),\n",
       " LabeledColumn([(u'\\u80fd',   1.28621757e-02), (u'\\u5929',   1.17718065e-02),\n",
       "        (u'\\u81e3',   1.09651582e-02), ..., (u'\\u8ba8',   1.54701973e-09),\n",
       "        (u'\\u90d1',   1.54701973e-09), (u'\\u9ad8',   1.54701973e-09)], \n",
       "       dtype=[('word', 'O'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.topics(print_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Document-topic probabilities\n",
    "The above code shows the topic-word distributions and allows us to estimate the quality of our topics.\n",
    "\n",
    "#### `v.labels`\n",
    "The property `v.labels` (without parentheses) returns a list of all documents in a corpus, and is useful for processing each document generically, wihtout having to look up the identifiers on the file system.\n",
    "\n",
    "Below, we print the first 3 document labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handian2/『史部』/职官/唐六典/卷十五·光禄寺.txt\n",
      "handian2/『史部』/职官/唐六典/卷二十八·太子左右卫及诸率府.txt\n",
      "handian2/『史部』/职官/唐六典/卷三·尚书户部.txt\n"
     ]
    }
   ],
   "source": [
    "for label in v.labels[:3]:\n",
    "    print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.doc_topics(doc_or_docs)`\n",
    "Each document-topic distribution can be examined with `v.doc_topics()`, which takes as its argument either a single label or a list of labels. Below we view the distribution for the first 3 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th style=\"text-align: center; background: #A9D0F5;            fontsize: 14px;\" colspan=\"6\"> Distributions over Topics </th></tr><tr><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: handian2/『史部』/职官/唐六典/卷十五·光禄寺.txt</th><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: handian2/『史部』/职官/唐六典/卷二十八·太子左右卫及诸率府.txt</th><th style=\"text-align: center; background: #CEE3F6;\"                 colspan=\"2\">Doc: handian2/『史部』/职官/唐六典/卷三·尚书户部.txt</th></tr><tr><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th><th style=\"text-align: center; background: #EFF2FB;\">                        Topic</th><th style=\"text-align: center; background: #EFF2FB;\">                        Prob</th></tr><tr><td>18</td><td>0.45781</td><td>0</td><td>0.64476</td><td>17</td><td>0.44986</td></tr><tr><td>0</td><td>0.30366</td><td>15</td><td>0.12606</td><td>6</td><td>0.20621</td></tr><tr><td>12</td><td>0.16860</td><td>2</td><td>0.08854</td><td>0</td><td>0.11983</td></tr><tr><td>5</td><td>0.04239</td><td>18</td><td>0.07904</td><td>12</td><td>0.04566</td></tr><tr><td>4</td><td>0.01630</td><td>14</td><td>0.06153</td><td>11</td><td>0.04494</td></tr><tr><td>8</td><td>0.00652</td><td>7</td><td>0.00001</td><td>13</td><td>0.03793</td></tr><tr><td>2</td><td>0.00466</td><td>1</td><td>0.00001</td><td>15</td><td>0.03262</td></tr><tr><td>17</td><td>0.00000</td><td>3</td><td>0.00001</td><td>18</td><td>0.02875</td></tr><tr><td>3</td><td>0.00000</td><td>4</td><td>0.00001</td><td>5</td><td>0.02283</td></tr><tr><td>16</td><td>0.00000</td><td>5</td><td>0.00001</td><td>4</td><td>0.00652</td></tr></table>"
      ],
      "text/plain": [
       "[LabeledColumn([(18,   4.57810134e-01), ( 0,   3.03655893e-01),\n",
       "        (12,   1.68596298e-01), ( 5,   4.23854291e-02),\n",
       "        ( 4,   1.63049586e-02), ( 8,   6.52478030e-03),\n",
       "        ( 2,   4.66188928e-03), (17,   4.65822268e-06),\n",
       "        ( 3,   4.65733410e-06), (16,   4.65733410e-06),\n",
       "        (15,   4.65733410e-06), (14,   4.65733410e-06),\n",
       "        (13,   4.65733410e-06), (11,   4.65733410e-06),\n",
       "        ( 7,   4.65733410e-06), ( 1,   4.65722314e-06),\n",
       "        (19,   4.65722314e-06), ( 6,   4.65722314e-06),\n",
       "        (10,   4.65722314e-06), ( 9,   4.65722314e-06)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([( 0,   6.44762874e-01), (15,   1.26055419e-01),\n",
       "        ( 2,   8.85404125e-02), (18,   7.90366083e-02),\n",
       "        (14,   6.15296103e-02), ( 7,   5.00211490e-06),\n",
       "        ( 1,   5.00211490e-06), ( 3,   5.00211490e-06),\n",
       "        ( 4,   5.00211490e-06), ( 5,   5.00211490e-06),\n",
       "        ( 6,   5.00211490e-06), (19,   5.00211490e-06),\n",
       "        ( 8,   5.00211490e-06), (10,   5.00211490e-06),\n",
       "        (11,   5.00211490e-06), (13,   5.00211490e-06),\n",
       "        (17,   5.00211490e-06), ( 9,   5.00211490e-06),\n",
       "        (12,   5.00199576e-06), (16,   5.00199576e-06)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')]),\n",
       " LabeledColumn([(17,   4.49857473e-01), ( 6,   2.06205472e-01),\n",
       "        ( 0,   1.19834036e-01), (12,   4.56633121e-02),\n",
       "        (11,   4.49385196e-02), (13,   3.79321650e-02),\n",
       "        (15,   3.26169990e-02), (18,   2.87514236e-02),\n",
       "        ( 5,   2.28322614e-02), ( 4,   6.52436679e-03),\n",
       "        ( 2,   3.38355778e-03), ( 7,   1.45079975e-03),\n",
       "        ( 1,   1.20917184e-06), (14,   1.20917184e-06),\n",
       "        ( 9,   1.20825030e-06), ( 8,   1.20801985e-06),\n",
       "        ( 3,   1.20801985e-06), (16,   1.20801985e-06),\n",
       "        (19,   1.20801985e-06), (10,   1.20799109e-06)], \n",
       "       dtype=[('topic', '<i8'), ('value', '<f4')])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.doc_topics(v.labels[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `v.aggregate_doc_topics(doc_or_docs, normed_sum=False)`\n",
    "While `v.doc_topics(doc_or_docs)` shows the distribution for each document, `v.aggregate_doc_topics()` shows the average distribution of a collection of documents. The `normed` argument tells the program whether to weight each document by its length (`normed_sum=True`) or to consider them all equally (`normed_sum=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"margin: 0\"><tr><th style=\"text-align: center; background: #CEE3F6\" colspan                    =\"2\">Aggregate Distribution over Topics</th></tr><tr><th style=\"text-align: center; background: #EFF2FB; \">Topic                          </th><th style=\"text-align: center; background: #EFF2FB; \">Prob                          </th></tr><tr><td>0                                      </td><td>0.35608                                </td></tr><tr><td>18                                     </td><td>0.18853                                </td></tr><tr><td>17                                     </td><td>0.14996                                </td></tr><tr><td>12                                     </td><td>0.07142                                </td></tr><tr><td>6                                      </td><td>0.06874                                </td></tr><tr><td>15                                     </td><td>0.05289                                </td></tr><tr><td>2                                      </td><td>0.03220                                </td></tr><tr><td>5                                      </td><td>0.02174                                </td></tr><tr><td>14                                     </td><td>0.02051                                </td></tr><tr><td>11                                     </td><td>0.01498                                </td></tr></table>"
      ],
      "text/plain": [
       "LabeledColumn([( 0,   3.56084228e-01), (18,   1.88532710e-01),\n",
       "       (17,   1.49955705e-01), (12,   7.14215338e-02),\n",
       "       ( 6,   6.87383711e-02), (15,   5.28923571e-02),\n",
       "       ( 2,   3.21952812e-02), ( 5,   2.17408966e-02),\n",
       "       (14,   2.05118246e-02), (11,   1.49827255e-02),\n",
       "       (13,   1.26472740e-02), ( 4,   7.61144189e-03),\n",
       "       ( 8,   2.17699655e-03), ( 7,   4.86819685e-04),\n",
       "       ( 1,   3.62283595e-06), ( 9,   3.62252899e-06),\n",
       "       ( 3,   3.62248920e-06), (19,   3.62245214e-06),\n",
       "       (16,   3.62244987e-06), (10,   3.62244259e-06)], \n",
       "      dtype=[('i', '<i8'), ('value', '<f4')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.aggregate_doc_topics(v.labels[:3], normed_sum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing documents with `v.dist()`\n",
    "\n",
    "Topic models give us a way to compare the siimilarity between two documents. To do this, we use `v.dist()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62897624160128662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.dist(v.labels[0], v.labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative distance measures\n",
    "By default, the Topic Explorer uses the Jensen-Shannon Distance to calculate the distance between documents. The Jensen-Shannon Distance (JSD) is a symmetric measure based on information theory that characterizes the difference between two probability distributions.\n",
    "\n",
    "However, several alternate methods are built into the `vsm.spatial` module. These include the Kullbeck-Liebler Divergence, which is an asymmetric component of the JSD and is used in [Murdock et al. (in review)](http://arxiv.org/abs/1509.07175) to characterize the cognitive surprise of a new text, given previous texts.\n",
    "\n",
    "Rather than using the JSD and assuming symmetric divergence between items, we assume that the second document is encountered after the first, effectively measuring text-to-text divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First to second 4.15705067559\n",
      "Second to first 3.57432545105\n"
     ]
    }
   ],
   "source": [
    "# first import KL divergence:\n",
    "from vsm.spatial import KL_div\n",
    "\n",
    "# calculate KL divergence from the first document to the second\n",
    "print \"First to second\", v.dist(v.labels[0], v.labels[1], dist_fn=KL_div)\n",
    "\n",
    "# calculate KL divergence from the second document to the first, highlighting asymmetry:\n",
    "print \"Second to first\", v.dist(v.labels[1], v.labels[0], dist_fn=KL_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python's Help System\n",
    "\n",
    "There are many other functions in the InPhO Topic Explorer and the associated `vsm` library. These are extensively documented within the code. \n",
    "\n",
    "One little-known feature about Python is its capacity for introspection: by using the `help()` method, one can find out all methods and properties of an object. For example, if one wanted to know what methods could be called on their corpus object, you could run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Corpus in module vsm.corpus.base object:\n",
      "\n",
      "class Corpus(BaseCorpus)\n",
      " |  The goal of the Corpus class is to provide an efficient representation    of a textual corpus.\n",
      " |  \n",
      " |  A Corpus object contains an integer representation of the text and\n",
      " |  maps to permit conversion between integer and string\n",
      " |  representations of a given word.\n",
      " |  \n",
      " |  As a BaseCorpus object, it includes a dictionary of tokenizations\n",
      " |  of the corpus and a method for viewing (without copying) these\n",
      " |  tokenizations. This dictionary also stores metadata (e.g.,\n",
      " |  document names) associated with the available tokenizations.\n",
      " |  \n",
      " |  :param corpus: A string array representing the corpus as a sequence of\n",
      " |      atomic words.\n",
      " |  :type corpus: array-like\n",
      " |  \n",
      " |  :param context_data: Each element in `context_data` is an array containing \n",
      " |      the indices marking the token boundaries. An element in `context_data` is\n",
      " |      intended for use as a value for the `indices_or_sections`\n",
      " |      parameter in `numpy.split`. Elements of `context_data` may also be\n",
      " |      1-D arrays whose elements are pairs, where the first element\n",
      " |      is a context boundary and the second element is metadata\n",
      " |      associated with that context preceding that boundary. For\n",
      " |      example, (250, 'dogs') might indicate that the 'article' context\n",
      " |      ending at the 250th word of the corpus is named 'dogs'.\n",
      " |      Default is `None`.\n",
      " |  :type context_data: list-like with 1-D integer array-like elements, optional\n",
      " |  \n",
      " |  :param context_types: Each element in `context_types` is a type of a context\n",
      " |      in `context_data`.\n",
      " |  :type context_types: array-like, optional\n",
      " |  \n",
      " |  :attributes: \n",
      " |      * **corpus** (1-D 32-bit integer array)\n",
      " |          corpus is the integer representation of the input string array-like\n",
      " |          value of the corpus parameter\n",
      " |      * **words** (1-D string array)\n",
      " |          The indexed set of strings occurring in corpus. It is a string-typed array.\n",
      " |      * **words_in** (1-D 32-bit integer dictionary)\n",
      " |          A dictionary whose keys are `words` and whose values are their \n",
      " |          corresponding integers (i.e., indices in `words`).\n",
      " |      \n",
      " |  :methods:\n",
      " |      * **view_metadata**\n",
      " |          Takes a type of tokenization and returns a view of the metadata\n",
      " |          of the tokenization.\n",
      " |      * **view_contexts**\n",
      " |          Takes a type of tokenization and returns a view of the corpus tokenized\n",
      " |          accordingly. The optional parameter `strings` takes a boolean value: \n",
      " |          True to view string representations of words; False to view integer \n",
      " |          representations of words. Default is `False`.\n",
      " |      * **save**\n",
      " |          Takes a filename and saves the data contained in a Corpus object to \n",
      " |          a `npy` file using `numpy.savez`.\n",
      " |      * **load**\n",
      " |          Static method. Takes a filename, loads the file data into a Corpus\n",
      " |          object and returns the object.\n",
      " |      * **apply_stoplist**\n",
      " |          Takes a list of stopwords and returns a copy of the corpus with \n",
      " |          the stopwords removed.\n",
      " |      * **tolist**\n",
      " |          Returns Corpus object as a list of lists of either integers or strings, \n",
      " |          according to `as_strings`.\n",
      " |      \n",
      " |  :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  **Examples**\n",
      " |  \n",
      " |  >>> text = ['I', 'came', 'I', 'saw', 'I', 'conquered']\n",
      " |  >>> context_types = ['sentences']\n",
      " |  >>> context_data = [np.array([(2, 'Veni'), (4, 'Vidi'), (6, 'Vici')],\n",
      " |                          dtype=[('idx', '<i8'), ('sent_label', '|S6')])]\n",
      " |  \n",
      " |  >>> from vsm.corpus import Corpus\n",
      " |  >>> c = Corpus(text, context_types=context_types, context_data=context_data)\n",
      " |  >>> c.corpus\n",
      " |  array([0, 1, 0, 2, 0, 3], dtype=int32)\n",
      " |  \n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'saw', 'conquered'],\n",
      " |        dtype='|S9')\n",
      " |  \n",
      " |  >>> c.words_int['saw']\n",
      " |  2\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences')\n",
      " |  [array([0, 3], dtype=int32), array([0, 2], dtype=int32),\n",
      " |   array([0, 1], dtype=int32)]\n",
      " |  \n",
      " |  >>> c.view_contexts('sentences', as_strings=True)\n",
      " |  [array(['I', 'came'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'saw'], \n",
      " |        dtype='|S9'),\n",
      " |   array(['I', 'conquered'], \n",
      " |        dtype='|S9')]\n",
      " |  \n",
      " |  >>> c.view_metadata('sentences')[1]['sent_label']\n",
      " |  'Vidi'\n",
      " |  \n",
      " |  >>> c = c.apply_stoplist(['saw'])\n",
      " |  >>> c.words\n",
      " |  array(['I', 'came', 'conquered'], \n",
      " |    dtype='|S9')\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Corpus\n",
      " |      BaseCorpus\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __init__(self, corpus, context_types=[], context_data=[], remove_empty=True)\n",
      " |  \n",
      " |  apply_stoplist(self, stoplist=[], freq=0)\n",
      " |      Takes a Corpus object and returns a copy of it with words in the\n",
      " |      stoplist removed and with words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  in_place_stoplist(self, stoplist=None, freq=0)\n",
      " |      Changes a Corpus object with words in the stoplist removed and with \n",
      " |      words of frequency <= `freq` removed.\n",
      " |      \n",
      " |      :param stoplist: The list of words to be removed.\n",
      " |      :type stoplist: list\n",
      " |      \n",
      " |      :param freq: A threshold where words of frequency <= 'freq' are\n",
      " |          removed. Default is 0.\n",
      " |      :type freq: integer, optional\n",
      " |          \n",
      " |      :returns: Copy of corpus with words in the stoplist and words\n",
      " |          of frequnecy <= 'freq' removed.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`\n",
      " |  \n",
      " |  save = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  tolist(self, context_type, as_strings=False)\n",
      " |      Returns Corpus object as a list of lists of either integers or\n",
      " |      strings, according to `as_strings`.\n",
      " |      \n",
      " |      :param context_type: The type of tokenization.\n",
      " |      :type context_type: string\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :returns: List of lists\n",
      " |  \n",
      " |  view_contexts(self, ctx_type, as_strings=False, as_slices=False, as_indices=False)\n",
      " |      Displays a tokenization of the corpus.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param as_strings: If True, string representations of words are returned.\n",
      " |          Otherwise, integer representations are returned. Default\n",
      " |          is `False`.\n",
      " |      :type as_strings: Boolean, optional\n",
      " |      \n",
      " |      :param as_slices: If True, a list of slices corresponding to 'ctx_type'\n",
      " |          is returned. Otherwise, integer representations are returned.\n",
      " |          Default is `False`.\n",
      " |      :type as_slices: Boolean, optional\n",
      " |      \n",
      " |      :returns: A tokenized view of `corpus`.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :class:`BaseCorpus`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  load(file=None, corpus_dir=None, corpus_file='corpus.npy', words_file='words.npy', metadata_file='metadata.npy')\n",
      " |      Loads data into a Corpus object. \n",
      " |      \n",
      " |      :param file: The file to read. See `numpy.load` for further\n",
      " |          details. Assumes file has been constructed as by\n",
      " |          `Corpus.save`. This option is exclusive of `corpus_dir`.\n",
      " |      :type file: str-like or file object\n",
      " |      \n",
      " |      :param corpus_dir: A directory containing the files\n",
      " |      `corpus_file`, `words_file`, `metadata_file`, from which to\n",
      " |      instantiate a Corpus object. This option is ignored if `file`\n",
      " |      is not `None`.\n",
      " |      :type corpus_dir: string\n",
      " |      \n",
      " |      :param corpus_file: File under `corpus_dir` containing the\n",
      " |      corpus data, stored as a numpy array of integers in an `npy`\n",
      " |      file.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :param words_file: File under `corpus_dir` containing the\n",
      " |      corpus vocabulary, stored as a numpy array of strings in an\n",
      " |      `npy` file.  \n",
      " |      :type words_file: string or file object\n",
      " |      \n",
      " |      :param metadata_file: File under `corpus_dir` containing the\n",
      " |      corpus metadata, stored as a numpy stuctured array in an `npy`\n",
      " |      file. Note that this structured array should contain a file\n",
      " |      `idx` which stores the integer indices marking the document\n",
      " |      boundaries.\n",
      " |      :type corpus_file: string or file object\n",
      " |      \n",
      " |      :returns: A Corpus object.\n",
      " |      \n",
      " |      :See Also: :class:`Corpus`, :meth:`Corpus.save`, :meth:`numpy.load`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  context_data\n",
      " |  \n",
      " |  context_types\n",
      " |  \n",
      " |  corpus\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  stopped_words\n",
      " |  \n",
      " |  words\n",
      " |  \n",
      " |  words_int\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCorpus:\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of tokens in the corpus.\n",
      " |      \n",
      " |      :See Also: `len(self.words)` for the number of unique tokens.\n",
      " |  \n",
      " |  get_metadatum(self, ctx_type, query, field)\n",
      " |      Returns the metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :param field: Field of the metadata\n",
      " |      :type field: string\n",
      " |      \n",
      " |      :returns: The metadatum corresponding to the query and the field.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  meta_int(self, ctx_type, query)\n",
      " |      Returns the index of the metadata found in the query.\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :param query: Dictionary with a key, value being a field, label\n",
      " |          in metadata.\n",
      " |      :type query: dictionary-like\n",
      " |      \n",
      " |      :returns: The index of the metadata found in the query.\n",
      " |      \n",
      " |      :raises: KeyError\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`\n",
      " |  \n",
      " |  remove_empty(self)\n",
      " |      Removes empty tokenizations, if `Corpus` object is not empty.\n",
      " |  \n",
      " |  view_metadata(self, ctx_type)\n",
      " |      Displays the metadata corresponding to a tokenization of the\n",
      " |      corpus. This method can be used in :class:`Corpus` as well as\n",
      " |      :class:`BaseCorpus`\n",
      " |      \n",
      " |      :param ctx_type: The type of a tokenization.\n",
      " |      :type ctx_type: string-like\n",
      " |      \n",
      " |      :returns: The metadata for a tokenization.\n",
      " |      \n",
      " |      :See Also: :class:`BaseCorpus`, :class:`Corpus`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get help on particular methods. For example, there are many arguments to `v.topics()` beyond `print_len`. These can be seen by calling `help(v.topics)` without parentheses after `v.topics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method topics in module vsm.viewer.ldacgsviewer:\n",
      "\n",
      "topics(self, topic_indices=None, sort=None, print_len=10, as_strings=True, compact_view=True, topic_labels=None) method of vsm.viewer.ldacgsviewer.LdaCgsViewer instance\n",
      "    Returns a list of topics estimated by the model. \n",
      "    Each topic is represented by a list of words and the corresponding \n",
      "    probabilities.\n",
      "    \n",
      "    :param topic_indices: List of indices of topics to be\n",
      "        displayed. Default is all topics.\n",
      "    :type topic_indices: list of integers\n",
      "    \n",
      "    :param sort: Topic sort function.\n",
      "    :type sort: string, values are \"entropy\", \"oscillation\", \"index\", \"jsd\",\n",
      "        \"user\" (default if topic_indices set), \"index\" (default)\n",
      "    \n",
      "    :param print_len: Number of words shown for each topic. Default is 10.\n",
      "    :type print_len: int, optional\n",
      "    \n",
      "    :param as_string: If `True`, each topic displays words rather than its\n",
      "        integer representation. Default is `True`.\n",
      "    :type as_string: boolean, optional\n",
      "    \n",
      "    :param compact_view: If `True`, topics are simply represented as\n",
      "        their top `print_len` number of words. Otherwise, topics are\n",
      "        shown as words and their probabilities. Default is `True`.\n",
      "    :type compact_view: boolean, optional       \n",
      "    \n",
      "    :param topic_labels: List of strings that are names that correspond\n",
      "        to the topics in `topic_indices`.\n",
      "    :type topic_labels: list, optional\n",
      "    \n",
      "    :returns: an instance of :class:`DataTable`.\n",
      "        A structured array of topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(v.topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `help(v.topics())` *with* parentheses will return help for the object reutrned by `v.topics()`, which is a `DataTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataTable in module vsm.viewer.labeleddata object:\n",
      "\n",
      "class DataTable(__builtin__.list)\n",
      " |  A subclass of list whose purpose is to store labels and\n",
      " |  formatting information for a list of 1-dimensional structured\n",
      " |  arrays. It also provides pretty-printing routines.\n",
      " |  \n",
      " |  Globally, the table has a default display length for the columns\n",
      " |  and a table header.\n",
      " |  \n",
      " |  A column can have a column-specific header.\n",
      " |  \n",
      " |  A subcolumn wraps the data found under a given field name. Each\n",
      " |  subcolumn has a label and a display width.\n",
      " |  \n",
      " |  :param l: List of 1-dimensional structured arrays.\n",
      " |  :type l: list\n",
      " |  \n",
      " |  :param table_header: The title of the object. Default is `None`.\n",
      " |  :type table_header: string, optional\n",
      " |  \n",
      " |  :param compact_view: If `True` the DataTable is displayed with its\n",
      " |      tokens only without the probabilities. Default is `True`\n",
      " |  :type compact_view: boolean, optional\n",
      " |  \n",
      " |  :attributes:\n",
      " |      * **table_header** (string)\n",
      " |          The title of the object. Default is `None`.\n",
      " |      * **compact_view** (boolean)\n",
      " |          Option of viewing tokens with or without the probabilities.\n",
      " |  :methods:\n",
      " |      * **__str__**\n",
      " |          Returns a pretty printed string version of the object.\n",
      " |      * **_repr_html_**\n",
      " |          Returns an html table in ipython online session.\n",
      " |  \n",
      " |  **Examples**\n",
      " |  \n",
      " |  >>>  words = ['there','will','be','an','answer']\n",
      " |  >>>  values = [random.random() for w in words]\n",
      " |  >>>  arr = np.array(zip(words, values), \n",
      " |          dtype=[('i', np.array(words).dtype), \n",
      " |          ('value', np.array(values).dtype)])\n",
      " |  >>>  lc = LabeledColumn(arr, 'Lyrics')\n",
      " |  >>>  l = [lc.copy() for i in xrange(2)]\n",
      " |  >>>  dt = DataTable(l, 'Let it be', subcolhdr_compact=['Topic', 'Words'],\n",
      " |                 subcolhdr_full=['Word', 'Prob'], compact_view=True)\n",
      " |  >>>  print dt\n",
      " |  --------------------------------------------\n",
      " |                   Let it be                  \n",
      " |  --------------------------------------------\n",
      " |  Topic      Words      \n",
      " |  --------------------------------------------\n",
      " |  Lyrics     there      will       be         \n",
      " |             an         answer     \n",
      " |  --------------------------------------------\n",
      " |  Lyrics     there      will       be         \n",
      " |             an         answer     \n",
      " |  --------------------------------------------\n",
      " |  \n",
      " |  >>> dt.compact_view = False\n",
      " |  >>>  print dt\n",
      " |      Let it be      \n",
      " |  ---------------------\n",
      " |          Words        \n",
      " |  ---------------------\n",
      " |  Word       Value     \n",
      " |  ---------------------\n",
      " |  there      0.58793   \n",
      " |  will       0.29624   \n",
      " |  be         0.00209   \n",
      " |  an         0.27221   \n",
      " |  answer     0.96118   \n",
      " |  ---------------------\n",
      " |          Words        \n",
      " |  ---------------------\n",
      " |  Word       Value     \n",
      " |  ---------------------\n",
      " |  there      0.22608   \n",
      " |  will       0.64567   \n",
      " |  be         0.02832   \n",
      " |  an         0.31118   \n",
      " |  answer     0.23083\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataTable\n",
      " |      __builtin__.list\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getslice__(self, i, j)\n",
      " |  \n",
      " |  __init__(self, l, table_header=None, compact_view=True, subcolhdr_compact=None, subcolhdr_full=None)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Pretty prints the DataTable when `print` method is used.\n",
      " |  \n",
      " |  __str_compact__(self, subcol_headers)\n",
      " |      Prints DataTable when `compact_view` is `True`.\n",
      " |  \n",
      " |  __str_full__(self, subcol_headers)\n",
      " |      Prints DataTable when `compact_view` is `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from __builtin__.list:\n",
      " |  \n",
      " |  __add__(...)\n",
      " |      x.__add__(y) <==> x+y\n",
      " |  \n",
      " |  __contains__(...)\n",
      " |      x.__contains__(y) <==> y in x\n",
      " |  \n",
      " |  __delitem__(...)\n",
      " |      x.__delitem__(y) <==> del x[y]\n",
      " |  \n",
      " |  __delslice__(...)\n",
      " |      x.__delslice__(i, j) <==> del x[i:j]\n",
      " |      \n",
      " |      Use of negative indices is not supported.\n",
      " |  \n",
      " |  __eq__(...)\n",
      " |      x.__eq__(y) <==> x==y\n",
      " |  \n",
      " |  __ge__(...)\n",
      " |      x.__ge__(y) <==> x>=y\n",
      " |  \n",
      " |  __getattribute__(...)\n",
      " |      x.__getattribute__('name') <==> x.name\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(...)\n",
      " |      x.__gt__(y) <==> x>y\n",
      " |  \n",
      " |  __iadd__(...)\n",
      " |      x.__iadd__(y) <==> x+=y\n",
      " |  \n",
      " |  __imul__(...)\n",
      " |      x.__imul__(y) <==> x*=y\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      x.__iter__() <==> iter(x)\n",
      " |  \n",
      " |  __le__(...)\n",
      " |      x.__le__(y) <==> x<=y\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      x.__len__() <==> len(x)\n",
      " |  \n",
      " |  __lt__(...)\n",
      " |      x.__lt__(y) <==> x<y\n",
      " |  \n",
      " |  __mul__(...)\n",
      " |      x.__mul__(n) <==> x*n\n",
      " |  \n",
      " |  __ne__(...)\n",
      " |      x.__ne__(y) <==> x!=y\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      L.__reversed__() -- return a reverse iterator over the list\n",
      " |  \n",
      " |  __rmul__(...)\n",
      " |      x.__rmul__(n) <==> n*x\n",
      " |  \n",
      " |  __setitem__(...)\n",
      " |      x.__setitem__(i, y) <==> x[i]=y\n",
      " |  \n",
      " |  __setslice__(...)\n",
      " |      x.__setslice__(i, j, y) <==> x[i:j]=y\n",
      " |      \n",
      " |      Use  of negative indices is not supported.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      L.__sizeof__() -- size of L in memory, in bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      L.append(object) -- append object to end\n",
      " |  \n",
      " |  count(...)\n",
      " |      L.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  extend(...)\n",
      " |      L.extend(iterable) -- extend list by appending elements from the iterable\n",
      " |  \n",
      " |  index(...)\n",
      " |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(...)\n",
      " |      L.insert(index, object) -- insert object before index\n",
      " |  \n",
      " |  pop(...)\n",
      " |      L.pop([index]) -> item -- remove and return item at index (default last).\n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |  \n",
      " |  remove(...)\n",
      " |      L.remove(value) -- remove first occurrence of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  reverse(...)\n",
      " |      L.reverse() -- reverse *IN PLACE*\n",
      " |  \n",
      " |  sort(...)\n",
      " |      L.sort(cmp=None, key=None, reverse=False) -- stable sort *IN PLACE*;\n",
      " |      cmp(x, y) -> -1, 0, 1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from __builtin__.list:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __new__ = <built-in method __new__ of type object>\n",
      " |      T.__new__(S, ...) -> a new object with type S, a subtype of T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(v.topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to emphasize that this functionality can be used with any python library, including the standard library. For example, one could look at all the functions included in the `math` library by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function log in module math:\n",
      "\n",
      "log(...)\n",
      "    log(x[, base])\n",
      "    \n",
      "    Return the logarithm of x to the given base.\n",
      "    If the base not specified, returns the natural logarithm (base e) of x.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "help(math.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6654de9f6664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m slice_idxs = [range(s.start,s.stop) for i, s in enumerate(v.corpus.view_contexts('document',as_slices=True)) \n\u001b[0;32m----> 2\u001b[0;31m                       if i in docs]\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "slice_idxs = [range(s.start,s.stop) for i, s in enumerate(v.corpus.view_contexts('document',as_slices=True)) \n",
    "                      if i in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "new_corpus = copy.deepcopy(v.corpus)\n",
    "print new_corpus\n",
    "print v.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_labels = [v._res_doc_type(d) for d in v.labels]\n",
    "docs, labels = zip(*docs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in v.corpus.view_contexts('document'):\n",
    "    print len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Examples\n",
    "\n",
    "This notebook gives some basic building blocks for using the Topic Explorer. Additional examples can be found on GitHub in the [inpho/vsm-demo-notebooks repository](http://github.com/inpho/vsm-demo-notebooks).\n",
    "\n",
    "# Contact Information\n",
    "If you have additional questions regarding the InPhO Topic Explorer or have comments on this tutorial, please e-mail [tutorial@hypershelf.org](mailto:tutorial@hypershelf.org).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
